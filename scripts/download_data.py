# -*- coding: utf-8 -*-
"""Untitled36.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-2rg_qZrRFOhsjpfcyBuQIA6EPQJ2wZA
"""

# scripts/download_data.py

import requests # type: ignore
import os

# Define the base URL and parameters
base_url = "https://d37ci6vzurychx.cloudfront.net/trip-data/"
file_format = "parquet"  # Use 'csv' if you prefer, but Parquet is better
taxi_type = "yellow"     # You can change this to "green" or "fhv"

# Create the data directory if it doesn't exist
os.makedirs("../data", exist_ok=True)

# Define the months we want: Aug 2023 to July 2024
months = [
    ('2023', '08'), ('2023', '09'), ('2023', '10'), ('2023', '11'), ('2023', '12'),
    ('2024', '01'), ('2024', '02'), ('2024', '03'), ('2024', '04'), ('2024', '05'),
    ('2024', '06'), ('2024', '07')
]

print("Starting download of NYC Taxi data...")

for year, month in months:
    # Construct the filename, e.g., yellow_tripdata_2023-08.parquet
    file_name = f"{taxi_type}_tripdata_{year}-{month}.{file_format}"
    url = base_url + file_name
    local_filepath = os.path.join("../data", file_name)

    print(f"Downloading {file_name}...")

    # Download the file
    response = requests.get(url, stream=True)
    response.raise_for_status()  # Check if the request was successful

    # Save the file to the data directory
    with open(local_filepath, 'wb') as f:
        for chunk in response.iter_content(chunk_size=8192):
            f.write(chunk)

    print(f"Saved to {local_filepath}")

print("All downloads complete!")

#pip install pandas pyarrow

import pandas as pd
import os

# Define paths
input_file = "../data/yellow_tripdata_2023-08.parquet"  # Using one month as an example
output_file = "../data/sample_yellow_tripdata_2023-08.csv"

print(f"Reading a sample from {input_file}...")

# Read the Parquet file. Use nrows to only read a sample of rows.
# Reading 10,000 rows is enough for analysis in a notebook.
df = pd.read_parquet(input_file) # Pandas will automatically use PyArrow

# Take a sample of 10,000 rows if the file is large
# If you want a specific sample size, you can use: df = df.sample(n=10000, random_state=42)
print(f"DataFrame shape: {df.shape}")

print(f"Saving sample to {output_file}...")
# Save the sampled data to a CSV file
df.to_csv(output_file, index=False)

print("Sample CSV created successfully!")