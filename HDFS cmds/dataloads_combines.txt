Microsoft Windows [Version 10.0.19045.6216]
(c) Microsoft Corporation. All rights reserved.

C:\Windows\system32>cd C:\MIT805_A1_Data\scripts

C:\MIT805_A1_Data\scripts>python hstatistics.py
Downloading sample data from HDFS...
Found CSV file: /MIT805A1/combined_all_taxi_data/nyc_all_taxi_data_2023_2024_combined.csv (10.2 GB)
âŒ Failed to download sample: 'head' is not recognized as an internal or external command,
operable program or batch file.

âŒ Could not download sample data

C:\MIT805_A1_Data\scripts>

C:\MIT805_A1_Data\scripts>python hstatistics.py
HDFS Dataset Statistics (Windows Compatible)
==================================================
âŒ Hadoop commands not available. Please check your Hadoop installation.
Make sure Hadoop bin directory is in your PATH environment variable.

C:\MIT805_A1_Data\scripts>python hstatistics.py
HDFS Dataset Statistics Generator
==================================================
âœ… Hadoop commands available
âœ… HDFS directory found: /MIT805A1/combined_all_taxi_data
Found 1 CSV file(s)
ðŸ“„ File: /MIT805A1/combined_all_taxi_data/nyc_all_taxi_data_2023_2024_combined.csv
ðŸ“Š Size: 9.53 GB
Downloading sample data...
âŒ Failed to download sample data

Generating basic statistics...

======================================================================
BASIC DATASET STATISTICS (Estimated)
======================================================================
Number of variables                              20
Number of observations                   51,172,344
File size                                      9.53 GB
HDFS path                      /MIT805A1/combined_all_taxi_data/nyc_all_taxi_data_2023_2024_combined.csv

C:\MIT805_A1_Data\scripts>python convert2024_csv.py
Creating 2023 CSV using local conversion...
Processing 2023-01...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-01.parquet...
  Converting to CSV...
  Converted to CSV: 48326 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-01
Processing 2023-02...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-02.parquet...
  Converting to CSV...
  Converted to CSV: 46621 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-02
Processing 2023-03...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-03.parquet...
  Converting to CSV...
  Converted to CSV: 51539 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-03
Processing 2023-04...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-04.parquet...
  Converting to CSV...
  Converted to CSV: 52132 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-04
Processing 2023-05...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-05.parquet...
  Converting to CSV...
  Converted to CSV: 55399 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-05
Processing 2023-06...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-06.parquet...
  Converting to CSV...
  Converted to CSV: 49390 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-06
Processing 2023-07...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-07.parquet...
  Converting to CSV...
  Converted to CSV: 48205 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-07
Processing 2023-08...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-08.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmph8c3byca\\temp_08.parquet'
Processing 2023-09...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-09.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmp8qkdcd10\\temp_09.parquet'
Processing 2023-10...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-10.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmphna9gc9r\\temp_10.parquet'
Processing 2023-11...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-11.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmpi0s_m755\\temp_11.parquet'
Processing 2023-12...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/green_tripdata_2025-12.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmp9mbmwtzg\\temp_12.parquet'
âœ… All 2025 files processed!
Final output in HDFS: /user/MukondeleliNegukhula/nyc_taxi/csv_green_2023/

Final output files:

C:\MIT805_A1_Data\scripts>python convert2024_csv.py
Creating 2023 CSV using local conversion...
Processing 2023-01...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-01.parquet...
  Converting to CSV...
  Converted to CSV: 3475226 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-01
Processing 2023-02...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-02.parquet...
  Converting to CSV...
  Converted to CSV: 3577543 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-02
Processing 2023-03...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-03.parquet...
  Converting to CSV...
  Converted to CSV: 4145257 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-03
Processing 2023-04...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-04.parquet...
  Converting to CSV...
  Converted to CSV: 3970553 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-04
Processing 2023-05...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-05.parquet...
  Converting to CSV...
  Converted to CSV: 4591845 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-05
Processing 2023-06...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-06.parquet...
  Converting to CSV...
  Converted to CSV: 4322960 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-06
Processing 2023-07...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-07.parquet...
  Converting to CSV...
  Converted to CSV: 3898963 rows
  Uploading to HDFS...
  âœ… Successfully processed 2025-07
Processing 2023-08...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-08.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmp9h0uv6vj\\temp_08.parquet'
Processing 2023-09...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-09.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmp4_71xlpo\\temp_09.parquet'
Processing 2023-10...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-10.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmpklae4t32\\temp_10.parquet'
Processing 2023-11...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-11.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmptpx3qfvv\\temp_11.parquet'
Processing 2023-12...
  Downloading /user/MukondeleliNegukhula/nyc_taxi/raw/yellow_tripdata_2025-12.parquet...
  Converting to CSV...
  âŒ Conversion failed: [Errno 2] No such file or directory: 'C:\\Users\\MUKOND~1\\AppData\\Local\\Temp\\tmpcgw6pl7o\\temp_12.parquet'
âœ… All 2025 files processed!
Final output in HDFS: /user/MukondeleliNegukhula/nyc_taxi/csv_yellow_2025/

Final output files:

C:\MIT805_A1_Data\scripts>python combine_csv_files.py
Combining 2025 CSV files and saving to /MIT805A1 folder...
Listing CSV files in HDFS...
Found 0 CSV files to process
âŒ No data frames to combine

C:\MIT805_A1_Data\scripts>python combine_csv_files.py
Combining 2025 CSV files and saving to /MIT805A1 folder...
Listing CSV files in HDFS...
Found 7 CSV files to process
Processing yellow_tripdata_2025-01.csv...
  Reading yellow_tripdata_2025-01.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3475226 rows with filedate: 2025-01-01
Processing yellow_tripdata_2025-02.csv...
  Reading yellow_tripdata_2025-02.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3577543 rows with filedate: 2025-02-01
Processing yellow_tripdata_2025-03.csv...
  Reading yellow_tripdata_2025-03.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4145257 rows with filedate: 2025-03-01
Processing yellow_tripdata_2025-04.csv...
  Reading yellow_tripdata_2025-04.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3970553 rows with filedate: 2025-04-01
Processing yellow_tripdata_2025-05.csv...
  Reading yellow_tripdata_2025-05.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4591845 rows with filedate: 2025-05-01
Processing yellow_tripdata_2025-06.csv...
  Reading yellow_tripdata_2025-06.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4322960 rows with filedate: 2025-06-01
Processing yellow_tripdata_2025-07.csv...
  Reading yellow_tripdata_2025-07.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3898963 rows with filedate: 2025-07-01
Combining all data...
Saving combined file with 27982347 rows...
Uploading to /MIT805A1/nyc_taxi_2025_combined_yellow.csv...
âœ… Successfully created combined file: /MIT805A1/nyc_taxi_2025_combined_yellow.csv
Verifying upload...

ðŸ“Š Combined File Statistics:
Total rows: 27,982,347
Total columns: 21
Date range: 2025-01-01 to 2025-07-01
File size: 3192.09 MB

Sample data with filedate:
     filedate  VendorID tpep_pickup_datetime tpep_dropoff_datetime
0  2025-01-01         1  2025-01-01 00:18:38   2025-01-01 00:26:59
1  2025-01-01         1  2025-01-01 00:32:40   2025-01-01 00:35:13
2  2025-01-01         1  2025-01-01 00:44:04   2025-01-01 00:46:01
3  2025-01-01         2  2025-01-01 00:14:27   2025-01-01 00:20:01
4  2025-01-01         2  2025-01-01 00:21:34   2025-01-01 00:25:06

First few rows with the new filedate column:
     filedate  VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count
0  2025-01-01         1  2025-01-01 00:18:38   2025-01-01 00:26:59              1.0
1  2025-01-01         1  2025-01-01 00:32:40   2025-01-01 00:35:13              1.0
2  2025-01-01         1  2025-01-01 00:44:04   2025-01-01 00:46:01              1.0
3  2025-01-01         2  2025-01-01 00:14:27   2025-01-01 00:20:01              3.0
4  2025-01-01         2  2025-01-01 00:21:34   2025-01-01 00:25:06              3.0

C:\MIT805_A1_Data\scripts>python combine_csv_files.py
Combining 2025 CSV files and saving to /MIT805A1 folder...
Listing CSV files in HDFS...
Found 7 CSV files to process
Processing yellow_tripdata_2025-01.csv...
  Reading yellow_tripdata_2025-01.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3475226 rows with filedate: 2025-01-01
Processing yellow_tripdata_2025-02.csv...
  Reading yellow_tripdata_2025-02.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3577543 rows with filedate: 2025-02-01
Processing yellow_tripdata_2025-03.csv...
  Reading yellow_tripdata_2025-03.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4145257 rows with filedate: 2025-03-01
Processing yellow_tripdata_2025-04.csv...
  Reading yellow_tripdata_2025-04.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3970553 rows with filedate: 2025-04-01
Processing yellow_tripdata_2025-05.csv...
  Reading yellow_tripdata_2025-05.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4591845 rows with filedate: 2025-05-01
Processing yellow_tripdata_2025-06.csv...
  Reading yellow_tripdata_2025-06.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 4322960 rows with filedate: 2025-06-01
Processing yellow_tripdata_2025-07.csv...
  Reading yellow_tripdata_2025-07.csv...
C:\MIT805_A1_Data\scripts\combine_csv_files.py:79: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  df = pd.read_csv(local_csv)
  âœ… Added 3898963 rows with filedate: 2025-07-01
Combining all data...
Saving combined file with 27982347 rows...
Uploading to /MIT805A1/nyc_taxi_2025_combined_yellow.csv...
âœ… Successfully created combined file: /MIT805A1/nyc_taxi_2025_combined_yellow.csv
Verifying upload...

ðŸ“Š Combined File Statistics:
Total rows: 27,982,347
Total columns: 21
Date range: 2025-01-01 to 2025-07-01
File size: 3192.09 MB

Sample data with filedate:
     filedate  VendorID tpep_pickup_datetime tpep_dropoff_datetime
0  2025-01-01         1  2025-01-01 00:18:38   2025-01-01 00:26:59
1  2025-01-01         1  2025-01-01 00:32:40   2025-01-01 00:35:13
2  2025-01-01         1  2025-01-01 00:44:04   2025-01-01 00:46:01
3  2025-01-01         2  2025-01-01 00:14:27   2025-01-01 00:20:01
4  2025-01-01         2  2025-01-01 00:21:34   2025-01-01 00:25:06

First few rows with the new filedate column:
     filedate  VendorID tpep_pickup_datetime tpep_dropoff_datetime  passenger_count
0  2025-01-01         1  2025-01-01 00:18:38   2025-01-01 00:26:59              1.0
1  2025-01-01         1  2025-01-01 00:32:40   2025-01-01 00:35:13              1.0
2  2025-01-01         1  2025-01-01 00:44:04   2025-01-01 00:46:01              1.0
3  2025-01-01         2  2025-01-01 00:14:27   2025-01-01 00:20:01              3.0
4  2025-01-01         2  2025-01-01 00:21:34   2025-01-01 00:25:06              3.0

C:\MIT805_A1_Data\scripts>python combine_all_csvs.py
Combining all taxi data (Yellow + Green) with file_source column
======================================================================
Processing yellow data: /MIT805A1/nyc_taxi_2023_combined_yellow.csv
Reading yellow data...
  Processed chunk 1: 100000 rows
  Processed chunk 2: 100000 rows
  Processed chunk 3: 100000 rows
  Processed chunk 4: 100000 rows
  Processed chunk 5: 100000 rows
  Processed chunk 6: 100000 rows
  Processed chunk 7: 100000 rows
  Processed chunk 8: 100000 rows
  Processed chunk 9: 100000 rows
  Processed chunk 10: 100000 rows
  Processed chunk 11: 100000 rows
  Processed chunk 12: 100000 rows
  Processed chunk 13: 100000 rows
  Processed chunk 14: 100000 rows
  Processed chunk 15: 100000 rows
  Processed chunk 16: 100000 rows
  Processed chunk 17: 100000 rows
  Processed chunk 18: 100000 rows
  Processed chunk 19: 100000 rows
  Processed chunk 20: 100000 rows
  Processed chunk 21: 100000 rows
  Processed chunk 22: 100000 rows
  Processed chunk 23: 100000 rows
  Processed chunk 24: 100000 rows
  Processed chunk 25: 100000 rows
  Processed chunk 26: 100000 rows
  Processed chunk 27: 100000 rows
  Processed chunk 28: 100000 rows
  Processed chunk 29: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 30: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 31: 100000 rows
  Processed chunk 32: 100000 rows
  Processed chunk 33: 100000 rows
  Processed chunk 34: 100000 rows
  Processed chunk 35: 100000 rows
  Processed chunk 36: 100000 rows
  Processed chunk 37: 100000 rows
  Processed chunk 38: 100000 rows
  Processed chunk 39: 100000 rows
  Processed chunk 40: 100000 rows
  Processed chunk 41: 100000 rows
  Processed chunk 42: 100000 rows
  Processed chunk 43: 100000 rows
  Processed chunk 44: 100000 rows
  Processed chunk 45: 100000 rows
  Processed chunk 46: 100000 rows
  Processed chunk 47: 100000 rows
  Processed chunk 48: 100000 rows
  Processed chunk 49: 100000 rows
  Processed chunk 50: 100000 rows
  Processed chunk 51: 100000 rows
  Processed chunk 52: 100000 rows
  Processed chunk 53: 100000 rows
  Processed chunk 54: 100000 rows
  Processed chunk 55: 100000 rows
  Processed chunk 56: 100000 rows
  Processed chunk 57: 100000 rows
  Processed chunk 58: 100000 rows
  Processed chunk 59: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 60: 100000 rows
  Processed chunk 61: 100000 rows
  Processed chunk 62: 100000 rows
  Processed chunk 63: 100000 rows
  Processed chunk 64: 100000 rows
  Processed chunk 65: 100000 rows
  Processed chunk 66: 100000 rows
  Processed chunk 67: 100000 rows
  Processed chunk 68: 100000 rows
  Processed chunk 69: 100000 rows
  Processed chunk 70: 100000 rows
  Processed chunk 71: 100000 rows
  Processed chunk 72: 100000 rows
  Processed chunk 73: 100000 rows
  Processed chunk 74: 100000 rows
  Processed chunk 75: 100000 rows
  Processed chunk 76: 100000 rows
  Processed chunk 77: 100000 rows
  Processed chunk 78: 100000 rows
  Processed chunk 79: 100000 rows
  Processed chunk 80: 100000 rows
  Processed chunk 81: 100000 rows
  Processed chunk 82: 100000 rows
  Processed chunk 83: 100000 rows
  Processed chunk 84: 100000 rows
  Processed chunk 85: 100000 rows
  Processed chunk 86: 100000 rows
  Processed chunk 87: 100000 rows
  Processed chunk 88: 100000 rows
  Processed chunk 89: 100000 rows
  Processed chunk 90: 100000 rows
  Processed chunk 91: 100000 rows
  Processed chunk 92: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 93: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 94: 100000 rows
  Processed chunk 95: 100000 rows
  Processed chunk 96: 100000 rows
  Processed chunk 97: 100000 rows
  Processed chunk 98: 100000 rows
  Processed chunk 99: 100000 rows
  Processed chunk 100: 100000 rows
  Processed chunk 101: 100000 rows
  Processed chunk 102: 100000 rows
  Processed chunk 103: 100000 rows
  Processed chunk 104: 100000 rows
  Processed chunk 105: 100000 rows
  Processed chunk 106: 100000 rows
  Processed chunk 107: 100000 rows
  Processed chunk 108: 100000 rows
  Processed chunk 109: 100000 rows
  Processed chunk 110: 100000 rows
  Processed chunk 111: 100000 rows
  Processed chunk 112: 100000 rows
  Processed chunk 113: 100000 rows
  Processed chunk 114: 100000 rows
  Processed chunk 115: 100000 rows
  Processed chunk 116: 100000 rows
  Processed chunk 117: 100000 rows
  Processed chunk 118: 100000 rows
  Processed chunk 119: 100000 rows
  Processed chunk 120: 100000 rows
  Processed chunk 121: 100000 rows
  Processed chunk 122: 100000 rows
  Processed chunk 123: 100000 rows
  Processed chunk 124: 100000 rows
  Processed chunk 125: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 126: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 127: 100000 rows
  Processed chunk 128: 100000 rows
  Processed chunk 129: 100000 rows
  Processed chunk 130: 100000 rows
  Processed chunk 131: 100000 rows
  Processed chunk 132: 100000 rows
  Processed chunk 133: 100000 rows
  Processed chunk 134: 100000 rows
  Processed chunk 135: 100000 rows
  Processed chunk 136: 100000 rows
  Processed chunk 137: 100000 rows
  Processed chunk 138: 100000 rows
  Processed chunk 139: 100000 rows
  Processed chunk 140: 100000 rows
  Processed chunk 141: 100000 rows
  Processed chunk 142: 100000 rows
  Processed chunk 143: 100000 rows
  Processed chunk 144: 100000 rows
  Processed chunk 145: 100000 rows
  Processed chunk 146: 100000 rows
  Processed chunk 147: 100000 rows
  Processed chunk 148: 100000 rows
  Processed chunk 149: 100000 rows
  Processed chunk 150: 100000 rows
  Processed chunk 151: 100000 rows
  Processed chunk 152: 100000 rows
  Processed chunk 153: 100000 rows
  Processed chunk 154: 100000 rows
  Processed chunk 155: 100000 rows
  Processed chunk 156: 100000 rows
  Processed chunk 157: 100000 rows
  Processed chunk 158: 100000 rows
  Processed chunk 159: 100000 rows
  Processed chunk 160: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 161: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 162: 100000 rows
  Processed chunk 163: 100000 rows
  Processed chunk 164: 100000 rows
  Processed chunk 165: 100000 rows
  Processed chunk 166: 100000 rows
  Processed chunk 167: 100000 rows
  Processed chunk 168: 100000 rows
  Processed chunk 169: 100000 rows
  Processed chunk 170: 100000 rows
  Processed chunk 171: 100000 rows
  Processed chunk 172: 100000 rows
  Processed chunk 173: 100000 rows
  Processed chunk 174: 100000 rows
  Processed chunk 175: 100000 rows
  Processed chunk 176: 100000 rows
  Processed chunk 177: 100000 rows
  Processed chunk 178: 100000 rows
  Processed chunk 179: 100000 rows
  Processed chunk 180: 100000 rows
  Processed chunk 181: 100000 rows
  Processed chunk 182: 100000 rows
  Processed chunk 183: 100000 rows
  Processed chunk 184: 100000 rows
  Processed chunk 185: 100000 rows
  Processed chunk 186: 100000 rows
  Processed chunk 187: 100000 rows
  Processed chunk 188: 100000 rows
  Processed chunk 189: 100000 rows
  Processed chunk 190: 100000 rows
  Processed chunk 191: 100000 rows
  Processed chunk 192: 100000 rows
  Processed chunk 193: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 194: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 195: 100000 rows
  Processed chunk 196: 100000 rows
  Processed chunk 197: 100000 rows
  Processed chunk 198: 100000 rows
  Processed chunk 199: 100000 rows
  Processed chunk 200: 100000 rows
  Processed chunk 201: 100000 rows
  Processed chunk 202: 100000 rows
  Processed chunk 203: 100000 rows
  Processed chunk 204: 100000 rows
  Processed chunk 205: 100000 rows
  Processed chunk 206: 100000 rows
  Processed chunk 207: 100000 rows
  Processed chunk 208: 100000 rows
  Processed chunk 209: 100000 rows
  Processed chunk 210: 100000 rows
  Processed chunk 211: 100000 rows
  Processed chunk 212: 100000 rows
  Processed chunk 213: 100000 rows
  Processed chunk 214: 100000 rows
  Processed chunk 215: 100000 rows
  Processed chunk 216: 100000 rows
  Processed chunk 217: 100000 rows
  Processed chunk 218: 100000 rows
  Processed chunk 219: 100000 rows
  Processed chunk 220: 100000 rows
  Processed chunk 221: 100000 rows
  Processed chunk 222: 100000 rows
  Processed chunk 223: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 224: 100000 rows
  Processed chunk 225: 100000 rows
  Processed chunk 226: 100000 rows
  Processed chunk 227: 100000 rows
  Processed chunk 228: 100000 rows
  Processed chunk 229: 100000 rows
  Processed chunk 230: 100000 rows
  Processed chunk 231: 100000 rows
  Processed chunk 232: 100000 rows
  Processed chunk 233: 100000 rows
  Processed chunk 234: 100000 rows
  Processed chunk 235: 100000 rows
  Processed chunk 236: 100000 rows
  Processed chunk 237: 100000 rows
  Processed chunk 238: 100000 rows
  Processed chunk 239: 100000 rows
  Processed chunk 240: 100000 rows
  Processed chunk 241: 100000 rows
  Processed chunk 242: 100000 rows
  Processed chunk 243: 100000 rows
  Processed chunk 244: 100000 rows
  Processed chunk 245: 100000 rows
  Processed chunk 246: 100000 rows
  Processed chunk 247: 100000 rows
  Processed chunk 248: 100000 rows
  Processed chunk 249: 100000 rows
  Processed chunk 250: 100000 rows
  Processed chunk 251: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 252: 100000 rows
  Processed chunk 253: 100000 rows
  Processed chunk 254: 100000 rows
  Processed chunk 255: 100000 rows
  Processed chunk 256: 100000 rows
  Processed chunk 257: 100000 rows
  Processed chunk 258: 100000 rows
  Processed chunk 259: 100000 rows
  Processed chunk 260: 100000 rows
  Processed chunk 261: 100000 rows
  Processed chunk 262: 100000 rows
  Processed chunk 263: 100000 rows
  Processed chunk 264: 100000 rows
  Processed chunk 265: 100000 rows
  Processed chunk 266: 100000 rows
  Processed chunk 267: 100000 rows
  Processed chunk 268: 100000 rows
  Processed chunk 269: 100000 rows
  Processed chunk 270: 100000 rows
  Processed chunk 271: 100000 rows
  Processed chunk 272: 100000 rows
  Processed chunk 273: 100000 rows
  Processed chunk 274: 100000 rows
  Processed chunk 275: 100000 rows
  Processed chunk 276: 100000 rows
  Processed chunk 277: 100000 rows
  Processed chunk 278: 100000 rows
  Processed chunk 279: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 280: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 281: 100000 rows
  Processed chunk 282: 100000 rows
  Processed chunk 283: 100000 rows
  Processed chunk 284: 100000 rows
  Processed chunk 285: 100000 rows
  Processed chunk 286: 100000 rows
  Processed chunk 287: 100000 rows
  Processed chunk 288: 100000 rows
  Processed chunk 289: 100000 rows
  Processed chunk 290: 100000 rows
  Processed chunk 291: 100000 rows
  Processed chunk 292: 100000 rows
  Processed chunk 293: 100000 rows
  Processed chunk 294: 100000 rows
  Processed chunk 295: 100000 rows
  Processed chunk 296: 100000 rows
  Processed chunk 297: 100000 rows
  Processed chunk 298: 100000 rows
  Processed chunk 299: 100000 rows
  Processed chunk 300: 100000 rows
  Processed chunk 301: 100000 rows
  Processed chunk 302: 100000 rows
  Processed chunk 303: 100000 rows
  Processed chunk 304: 100000 rows
  Processed chunk 305: 100000 rows
  Processed chunk 306: 100000 rows
  Processed chunk 307: 100000 rows
  Processed chunk 308: 100000 rows
  Processed chunk 309: 100000 rows
  Processed chunk 310: 100000 rows
  Processed chunk 311: 100000 rows
  Processed chunk 312: 100000 rows
  Processed chunk 313: 100000 rows
  Processed chunk 314: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 315: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 316: 100000 rows
  Processed chunk 317: 100000 rows
  Processed chunk 318: 100000 rows
  Processed chunk 319: 100000 rows
  Processed chunk 320: 100000 rows
  Processed chunk 321: 100000 rows
  Processed chunk 322: 100000 rows
  Processed chunk 323: 100000 rows
  Processed chunk 324: 100000 rows
  Processed chunk 325: 100000 rows
  Processed chunk 326: 100000 rows
  Processed chunk 327: 100000 rows
  Processed chunk 328: 100000 rows
  Processed chunk 329: 100000 rows
  Processed chunk 330: 100000 rows
  Processed chunk 331: 100000 rows
  Processed chunk 332: 100000 rows
  Processed chunk 333: 100000 rows
  Processed chunk 334: 100000 rows
  Processed chunk 335: 100000 rows
  Processed chunk 336: 100000 rows
  Processed chunk 337: 100000 rows
  Processed chunk 338: 100000 rows
  Processed chunk 339: 100000 rows
  Processed chunk 340: 100000 rows
  Processed chunk 341: 100000 rows
  Processed chunk 342: 100000 rows
  Processed chunk 343: 100000 rows
  Processed chunk 344: 100000 rows
  Processed chunk 345: 100000 rows
  Processed chunk 346: 100000 rows
  Processed chunk 347: 100000 rows
  Processed chunk 348: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 349: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 350: 100000 rows
  Processed chunk 351: 100000 rows
  Processed chunk 352: 100000 rows
  Processed chunk 353: 100000 rows
  Processed chunk 354: 100000 rows
  Processed chunk 355: 100000 rows
  Processed chunk 356: 100000 rows
  Processed chunk 357: 100000 rows
  Processed chunk 358: 100000 rows
  Processed chunk 359: 100000 rows
  Processed chunk 360: 100000 rows
  Processed chunk 361: 100000 rows
  Processed chunk 362: 100000 rows
  Processed chunk 363: 100000 rows
  Processed chunk 364: 100000 rows
  Processed chunk 365: 100000 rows
  Processed chunk 366: 100000 rows
  Processed chunk 367: 100000 rows
  Processed chunk 368: 100000 rows
  Processed chunk 369: 100000 rows
  Processed chunk 370: 100000 rows
  Processed chunk 371: 100000 rows
  Processed chunk 372: 100000 rows
  Processed chunk 373: 100000 rows
  Processed chunk 374: 100000 rows
  Processed chunk 375: 100000 rows
  Processed chunk 376: 100000 rows
  Processed chunk 377: 100000 rows
  Processed chunk 378: 100000 rows
  Processed chunk 379: 100000 rows
  Processed chunk 380: 100000 rows
  Processed chunk 381: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 382: 100000 rows
  Processed chunk 383: 100000 rows
  Processed chunk 384: 10226 rows
âœ… Processed 38,310,226 rows from yellow data
Processing yellow data: /MIT805A1/nyc_taxi_2024_combined_yellow.csv
Reading yellow data...
  Processed chunk 1: 100000 rows
  Processed chunk 2: 100000 rows
  Processed chunk 3: 100000 rows
  Processed chunk 4: 100000 rows
  Processed chunk 5: 100000 rows
  Processed chunk 6: 100000 rows
  Processed chunk 7: 100000 rows
  Processed chunk 8: 100000 rows
  Processed chunk 9: 100000 rows
  Processed chunk 10: 100000 rows
  Processed chunk 11: 100000 rows
  Processed chunk 12: 100000 rows
  Processed chunk 13: 100000 rows
  Processed chunk 14: 100000 rows
  Processed chunk 15: 100000 rows
  Processed chunk 16: 100000 rows
  Processed chunk 17: 100000 rows
  Processed chunk 18: 100000 rows
  Processed chunk 19: 100000 rows
  Processed chunk 20: 100000 rows
  Processed chunk 21: 100000 rows
  Processed chunk 22: 100000 rows
  Processed chunk 23: 100000 rows
  Processed chunk 24: 100000 rows
  Processed chunk 25: 100000 rows
  Processed chunk 26: 100000 rows
  Processed chunk 27: 100000 rows
  Processed chunk 28: 100000 rows
  Processed chunk 29: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 30: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 31: 100000 rows
  Processed chunk 32: 100000 rows
  Processed chunk 33: 100000 rows
  Processed chunk 34: 100000 rows
  Processed chunk 35: 100000 rows
  Processed chunk 36: 100000 rows
  Processed chunk 37: 100000 rows
  Processed chunk 38: 100000 rows
  Processed chunk 39: 100000 rows
  Processed chunk 40: 100000 rows
  Processed chunk 41: 100000 rows
  Processed chunk 42: 100000 rows
  Processed chunk 43: 100000 rows
  Processed chunk 44: 100000 rows
  Processed chunk 45: 100000 rows
  Processed chunk 46: 100000 rows
  Processed chunk 47: 100000 rows
  Processed chunk 48: 100000 rows
  Processed chunk 49: 100000 rows
  Processed chunk 50: 100000 rows
  Processed chunk 51: 100000 rows
  Processed chunk 52: 100000 rows
  Processed chunk 53: 100000 rows
  Processed chunk 54: 100000 rows
  Processed chunk 55: 100000 rows
  Processed chunk 56: 100000 rows
  Processed chunk 57: 100000 rows
  Processed chunk 58: 100000 rows
  Processed chunk 59: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 60: 100000 rows
  Processed chunk 61: 100000 rows
  Processed chunk 62: 100000 rows
  Processed chunk 63: 100000 rows
  Processed chunk 64: 100000 rows
  Processed chunk 65: 100000 rows
  Processed chunk 66: 100000 rows
  Processed chunk 67: 100000 rows
  Processed chunk 68: 100000 rows
  Processed chunk 69: 100000 rows
  Processed chunk 70: 100000 rows
  Processed chunk 71: 100000 rows
  Processed chunk 72: 100000 rows
  Processed chunk 73: 100000 rows
  Processed chunk 74: 100000 rows
  Processed chunk 75: 100000 rows
  Processed chunk 76: 100000 rows
  Processed chunk 77: 100000 rows
  Processed chunk 78: 100000 rows
  Processed chunk 79: 100000 rows
  Processed chunk 80: 100000 rows
  Processed chunk 81: 100000 rows
  Processed chunk 82: 100000 rows
  Processed chunk 83: 100000 rows
  Processed chunk 84: 100000 rows
  Processed chunk 85: 100000 rows
  Processed chunk 86: 100000 rows
  Processed chunk 87: 100000 rows
  Processed chunk 88: 100000 rows
  Processed chunk 89: 100000 rows
  Processed chunk 90: 100000 rows
  Processed chunk 91: 100000 rows
  Processed chunk 92: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 93: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 94: 100000 rows
  Processed chunk 95: 100000 rows
  Processed chunk 96: 100000 rows
  Processed chunk 97: 100000 rows
  Processed chunk 98: 100000 rows
  Processed chunk 99: 100000 rows
  Processed chunk 100: 100000 rows
  Processed chunk 101: 100000 rows
  Processed chunk 102: 100000 rows
  Processed chunk 103: 100000 rows
  Processed chunk 104: 100000 rows
  Processed chunk 105: 100000 rows
  Processed chunk 106: 100000 rows
  Processed chunk 107: 100000 rows
  Processed chunk 108: 100000 rows
  Processed chunk 109: 100000 rows
  Processed chunk 110: 100000 rows
  Processed chunk 111: 100000 rows
  Processed chunk 112: 100000 rows
  Processed chunk 113: 100000 rows
  Processed chunk 114: 100000 rows
  Processed chunk 115: 100000 rows
  Processed chunk 116: 100000 rows
  Processed chunk 117: 100000 rows
  Processed chunk 118: 100000 rows
  Processed chunk 119: 100000 rows
  Processed chunk 120: 100000 rows
  Processed chunk 121: 100000 rows
  Processed chunk 122: 100000 rows
  Processed chunk 123: 100000 rows
  Processed chunk 124: 100000 rows
  Processed chunk 125: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 126: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 127: 100000 rows
  Processed chunk 128: 100000 rows
  Processed chunk 129: 100000 rows
  Processed chunk 130: 100000 rows
  Processed chunk 131: 100000 rows
  Processed chunk 132: 100000 rows
  Processed chunk 133: 100000 rows
  Processed chunk 134: 100000 rows
  Processed chunk 135: 100000 rows
  Processed chunk 136: 100000 rows
  Processed chunk 137: 100000 rows
  Processed chunk 138: 100000 rows
  Processed chunk 139: 100000 rows
  Processed chunk 140: 100000 rows
  Processed chunk 141: 100000 rows
  Processed chunk 142: 100000 rows
  Processed chunk 143: 100000 rows
  Processed chunk 144: 100000 rows
  Processed chunk 145: 100000 rows
  Processed chunk 146: 100000 rows
  Processed chunk 147: 100000 rows
  Processed chunk 148: 100000 rows
  Processed chunk 149: 100000 rows
  Processed chunk 150: 100000 rows
  Processed chunk 151: 100000 rows
  Processed chunk 152: 100000 rows
  Processed chunk 153: 100000 rows
  Processed chunk 154: 100000 rows
  Processed chunk 155: 100000 rows
  Processed chunk 156: 100000 rows
  Processed chunk 157: 100000 rows
  Processed chunk 158: 100000 rows
  Processed chunk 159: 100000 rows
  Processed chunk 160: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 161: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 162: 100000 rows
  Processed chunk 163: 100000 rows
  Processed chunk 164: 100000 rows
  Processed chunk 165: 100000 rows
  Processed chunk 166: 100000 rows
  Processed chunk 167: 100000 rows
  Processed chunk 168: 100000 rows
  Processed chunk 169: 100000 rows
  Processed chunk 170: 100000 rows
  Processed chunk 171: 100000 rows
  Processed chunk 172: 100000 rows
  Processed chunk 173: 100000 rows
  Processed chunk 174: 100000 rows
  Processed chunk 175: 100000 rows
  Processed chunk 176: 100000 rows
  Processed chunk 177: 100000 rows
  Processed chunk 178: 100000 rows
  Processed chunk 179: 100000 rows
  Processed chunk 180: 100000 rows
  Processed chunk 181: 100000 rows
  Processed chunk 182: 100000 rows
  Processed chunk 183: 100000 rows
  Processed chunk 184: 100000 rows
  Processed chunk 185: 100000 rows
  Processed chunk 186: 100000 rows
  Processed chunk 187: 100000 rows
  Processed chunk 188: 100000 rows
  Processed chunk 189: 100000 rows
  Processed chunk 190: 100000 rows
  Processed chunk 191: 100000 rows
  Processed chunk 192: 100000 rows
  Processed chunk 193: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 194: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 195: 100000 rows
  Processed chunk 196: 100000 rows
  Processed chunk 197: 100000 rows
  Processed chunk 198: 100000 rows
  Processed chunk 199: 100000 rows
  Processed chunk 200: 100000 rows
  Processed chunk 201: 100000 rows
  Processed chunk 202: 100000 rows
  Processed chunk 203: 100000 rows
  Processed chunk 204: 100000 rows
  Processed chunk 205: 100000 rows
  Processed chunk 206: 100000 rows
  Processed chunk 207: 100000 rows
  Processed chunk 208: 100000 rows
  Processed chunk 209: 100000 rows
  Processed chunk 210: 100000 rows
  Processed chunk 211: 100000 rows
  Processed chunk 212: 100000 rows
  Processed chunk 213: 100000 rows
  Processed chunk 214: 100000 rows
  Processed chunk 215: 100000 rows
  Processed chunk 216: 100000 rows
  Processed chunk 217: 100000 rows
  Processed chunk 218: 100000 rows
  Processed chunk 219: 100000 rows
  Processed chunk 220: 100000 rows
  Processed chunk 221: 100000 rows
  Processed chunk 222: 100000 rows
  Processed chunk 223: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 224: 100000 rows
  Processed chunk 225: 100000 rows
  Processed chunk 226: 100000 rows
  Processed chunk 227: 100000 rows
  Processed chunk 228: 100000 rows
  Processed chunk 229: 100000 rows
  Processed chunk 230: 100000 rows
  Processed chunk 231: 100000 rows
  Processed chunk 232: 100000 rows
  Processed chunk 233: 100000 rows
  Processed chunk 234: 100000 rows
  Processed chunk 235: 100000 rows
  Processed chunk 236: 100000 rows
  Processed chunk 237: 100000 rows
  Processed chunk 238: 100000 rows
  Processed chunk 239: 100000 rows
  Processed chunk 240: 100000 rows
  Processed chunk 241: 100000 rows
  Processed chunk 242: 100000 rows
  Processed chunk 243: 100000 rows
  Processed chunk 244: 100000 rows
  Processed chunk 245: 100000 rows
  Processed chunk 246: 100000 rows
  Processed chunk 247: 100000 rows
  Processed chunk 248: 100000 rows
  Processed chunk 249: 100000 rows
  Processed chunk 250: 100000 rows
  Processed chunk 251: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 252: 100000 rows
  Processed chunk 253: 100000 rows
  Processed chunk 254: 100000 rows
  Processed chunk 255: 100000 rows
  Processed chunk 256: 100000 rows
  Processed chunk 257: 100000 rows
  Processed chunk 258: 100000 rows
  Processed chunk 259: 100000 rows
  Processed chunk 260: 100000 rows
  Processed chunk 261: 100000 rows
  Processed chunk 262: 100000 rows
  Processed chunk 263: 100000 rows
  Processed chunk 264: 100000 rows
  Processed chunk 265: 100000 rows
  Processed chunk 266: 100000 rows
  Processed chunk 267: 100000 rows
  Processed chunk 268: 100000 rows
  Processed chunk 269: 100000 rows
  Processed chunk 270: 100000 rows
  Processed chunk 271: 100000 rows
  Processed chunk 272: 100000 rows
  Processed chunk 273: 100000 rows
  Processed chunk 274: 100000 rows
  Processed chunk 275: 100000 rows
  Processed chunk 276: 100000 rows
  Processed chunk 277: 100000 rows
  Processed chunk 278: 100000 rows
  Processed chunk 279: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 280: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 281: 100000 rows
  Processed chunk 282: 100000 rows
  Processed chunk 283: 100000 rows
  Processed chunk 284: 100000 rows
  Processed chunk 285: 100000 rows
  Processed chunk 286: 100000 rows
  Processed chunk 287: 100000 rows
  Processed chunk 288: 100000 rows
  Processed chunk 289: 100000 rows
  Processed chunk 290: 100000 rows
  Processed chunk 291: 100000 rows
  Processed chunk 292: 100000 rows
  Processed chunk 293: 100000 rows
  Processed chunk 294: 100000 rows
  Processed chunk 295: 100000 rows
  Processed chunk 296: 100000 rows
  Processed chunk 297: 100000 rows
  Processed chunk 298: 100000 rows
  Processed chunk 299: 100000 rows
  Processed chunk 300: 100000 rows
  Processed chunk 301: 100000 rows
  Processed chunk 302: 100000 rows
  Processed chunk 303: 100000 rows
  Processed chunk 304: 100000 rows
  Processed chunk 305: 100000 rows
  Processed chunk 306: 100000 rows
  Processed chunk 307: 100000 rows
  Processed chunk 308: 100000 rows
  Processed chunk 309: 100000 rows
  Processed chunk 310: 100000 rows
  Processed chunk 311: 100000 rows
  Processed chunk 312: 100000 rows
  Processed chunk 313: 100000 rows
  Processed chunk 314: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 315: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 316: 100000 rows
  Processed chunk 317: 100000 rows
  Processed chunk 318: 100000 rows
  Processed chunk 319: 100000 rows
  Processed chunk 320: 100000 rows
  Processed chunk 321: 100000 rows
  Processed chunk 322: 100000 rows
  Processed chunk 323: 100000 rows
  Processed chunk 324: 100000 rows
  Processed chunk 325: 100000 rows
  Processed chunk 326: 100000 rows
  Processed chunk 327: 100000 rows
  Processed chunk 328: 100000 rows
  Processed chunk 329: 100000 rows
  Processed chunk 330: 100000 rows
  Processed chunk 331: 100000 rows
  Processed chunk 332: 100000 rows
  Processed chunk 333: 100000 rows
  Processed chunk 334: 100000 rows
  Processed chunk 335: 100000 rows
  Processed chunk 336: 100000 rows
  Processed chunk 337: 100000 rows
  Processed chunk 338: 100000 rows
  Processed chunk 339: 100000 rows
  Processed chunk 340: 100000 rows
  Processed chunk 341: 100000 rows
  Processed chunk 342: 100000 rows
  Processed chunk 343: 100000 rows
  Processed chunk 344: 100000 rows
  Processed chunk 345: 100000 rows
  Processed chunk 346: 100000 rows
  Processed chunk 347: 100000 rows
  Processed chunk 348: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 349: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 350: 100000 rows
  Processed chunk 351: 100000 rows
  Processed chunk 352: 100000 rows
  Processed chunk 353: 100000 rows
  Processed chunk 354: 100000 rows
  Processed chunk 355: 100000 rows
  Processed chunk 356: 100000 rows
  Processed chunk 357: 100000 rows
  Processed chunk 358: 100000 rows
  Processed chunk 359: 100000 rows
  Processed chunk 360: 100000 rows
  Processed chunk 361: 100000 rows
  Processed chunk 362: 100000 rows
  Processed chunk 363: 100000 rows
  Processed chunk 364: 100000 rows
  Processed chunk 365: 100000 rows
  Processed chunk 366: 100000 rows
  Processed chunk 367: 100000 rows
  Processed chunk 368: 100000 rows
  Processed chunk 369: 100000 rows
  Processed chunk 370: 100000 rows
  Processed chunk 371: 100000 rows
  Processed chunk 372: 100000 rows
  Processed chunk 373: 100000 rows
  Processed chunk 374: 100000 rows
  Processed chunk 375: 100000 rows
  Processed chunk 376: 100000 rows
  Processed chunk 377: 100000 rows
  Processed chunk 378: 100000 rows
  Processed chunk 379: 100000 rows
  Processed chunk 380: 100000 rows
  Processed chunk 381: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 382: 100000 rows
  Processed chunk 383: 100000 rows
  Processed chunk 384: 10226 rows
âœ… Processed 38,310,226 rows from yellow data
Processing yellow data: /MIT805A1/nyc_taxi_2025_combined_yellow.csv
Reading yellow data...
  Processed chunk 1: 100000 rows
  Processed chunk 2: 100000 rows
  Processed chunk 3: 100000 rows
  Processed chunk 4: 100000 rows
  Processed chunk 5: 100000 rows
  Processed chunk 6: 100000 rows
  Processed chunk 7: 100000 rows
  Processed chunk 8: 100000 rows
  Processed chunk 9: 100000 rows
  Processed chunk 10: 100000 rows
  Processed chunk 11: 100000 rows
  Processed chunk 12: 100000 rows
  Processed chunk 13: 100000 rows
  Processed chunk 14: 100000 rows
  Processed chunk 15: 100000 rows
  Processed chunk 16: 100000 rows
  Processed chunk 17: 100000 rows
  Processed chunk 18: 100000 rows
  Processed chunk 19: 100000 rows
  Processed chunk 20: 100000 rows
  Processed chunk 21: 100000 rows
  Processed chunk 22: 100000 rows
  Processed chunk 23: 100000 rows
  Processed chunk 24: 100000 rows
  Processed chunk 25: 100000 rows
  Processed chunk 26: 100000 rows
  Processed chunk 27: 100000 rows
  Processed chunk 28: 100000 rows
  Processed chunk 29: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 30: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 31: 100000 rows
  Processed chunk 32: 100000 rows
  Processed chunk 33: 100000 rows
  Processed chunk 34: 100000 rows
  Processed chunk 35: 100000 rows
  Processed chunk 36: 100000 rows
  Processed chunk 37: 100000 rows
  Processed chunk 38: 100000 rows
  Processed chunk 39: 100000 rows
  Processed chunk 40: 100000 rows
  Processed chunk 41: 100000 rows
  Processed chunk 42: 100000 rows
  Processed chunk 43: 100000 rows
  Processed chunk 44: 100000 rows
  Processed chunk 45: 100000 rows
  Processed chunk 46: 100000 rows
  Processed chunk 47: 100000 rows
  Processed chunk 48: 100000 rows
  Processed chunk 49: 100000 rows
  Processed chunk 50: 100000 rows
  Processed chunk 51: 100000 rows
  Processed chunk 52: 100000 rows
  Processed chunk 53: 100000 rows
  Processed chunk 54: 100000 rows
  Processed chunk 55: 100000 rows
  Processed chunk 56: 100000 rows
  Processed chunk 57: 100000 rows
  Processed chunk 58: 100000 rows
  Processed chunk 59: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 60: 100000 rows
  Processed chunk 61: 100000 rows
  Processed chunk 62: 100000 rows
  Processed chunk 63: 100000 rows
  Processed chunk 64: 100000 rows
  Processed chunk 65: 100000 rows
  Processed chunk 66: 100000 rows
  Processed chunk 67: 100000 rows
  Processed chunk 68: 100000 rows
  Processed chunk 69: 100000 rows
  Processed chunk 70: 100000 rows
  Processed chunk 71: 100000 rows
  Processed chunk 72: 100000 rows
  Processed chunk 73: 100000 rows
  Processed chunk 74: 100000 rows
  Processed chunk 75: 100000 rows
  Processed chunk 76: 100000 rows
  Processed chunk 77: 100000 rows
  Processed chunk 78: 100000 rows
  Processed chunk 79: 100000 rows
  Processed chunk 80: 100000 rows
  Processed chunk 81: 100000 rows
  Processed chunk 82: 100000 rows
  Processed chunk 83: 100000 rows
  Processed chunk 84: 100000 rows
  Processed chunk 85: 100000 rows
  Processed chunk 86: 100000 rows
  Processed chunk 87: 100000 rows
  Processed chunk 88: 100000 rows
  Processed chunk 89: 100000 rows
  Processed chunk 90: 100000 rows
  Processed chunk 91: 100000 rows
  Processed chunk 92: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 93: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 94: 100000 rows
  Processed chunk 95: 100000 rows
  Processed chunk 96: 100000 rows
  Processed chunk 97: 100000 rows
  Processed chunk 98: 100000 rows
  Processed chunk 99: 100000 rows
  Processed chunk 100: 100000 rows
  Processed chunk 101: 100000 rows
  Processed chunk 102: 100000 rows
  Processed chunk 103: 100000 rows
  Processed chunk 104: 100000 rows
  Processed chunk 105: 100000 rows
  Processed chunk 106: 100000 rows
  Processed chunk 107: 100000 rows
  Processed chunk 108: 100000 rows
  Processed chunk 109: 100000 rows
  Processed chunk 110: 100000 rows
  Processed chunk 111: 100000 rows
  Processed chunk 112: 100000 rows
  Processed chunk 113: 100000 rows
  Processed chunk 114: 100000 rows
  Processed chunk 115: 100000 rows
  Processed chunk 116: 100000 rows
  Processed chunk 117: 100000 rows
  Processed chunk 118: 100000 rows
  Processed chunk 119: 100000 rows
  Processed chunk 120: 100000 rows
  Processed chunk 121: 100000 rows
  Processed chunk 122: 100000 rows
  Processed chunk 123: 100000 rows
  Processed chunk 124: 100000 rows
  Processed chunk 125: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 126: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 127: 100000 rows
  Processed chunk 128: 100000 rows
  Processed chunk 129: 100000 rows
  Processed chunk 130: 100000 rows
  Processed chunk 131: 100000 rows
  Processed chunk 132: 100000 rows
  Processed chunk 133: 100000 rows
  Processed chunk 134: 100000 rows
  Processed chunk 135: 100000 rows
  Processed chunk 136: 100000 rows
  Processed chunk 137: 100000 rows
  Processed chunk 138: 100000 rows
  Processed chunk 139: 100000 rows
  Processed chunk 140: 100000 rows
  Processed chunk 141: 100000 rows
  Processed chunk 142: 100000 rows
  Processed chunk 143: 100000 rows
  Processed chunk 144: 100000 rows
  Processed chunk 145: 100000 rows
  Processed chunk 146: 100000 rows
  Processed chunk 147: 100000 rows
  Processed chunk 148: 100000 rows
  Processed chunk 149: 100000 rows
  Processed chunk 150: 100000 rows
  Processed chunk 151: 100000 rows
  Processed chunk 152: 100000 rows
  Processed chunk 153: 100000 rows
  Processed chunk 154: 100000 rows
  Processed chunk 155: 100000 rows
  Processed chunk 156: 100000 rows
  Processed chunk 157: 100000 rows
  Processed chunk 158: 100000 rows
  Processed chunk 159: 100000 rows
  Processed chunk 160: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 161: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 162: 100000 rows
  Processed chunk 163: 100000 rows
  Processed chunk 164: 100000 rows
  Processed chunk 165: 100000 rows
  Processed chunk 166: 100000 rows
  Processed chunk 167: 100000 rows
  Processed chunk 168: 100000 rows
  Processed chunk 169: 100000 rows
  Processed chunk 170: 100000 rows
  Processed chunk 171: 100000 rows
  Processed chunk 172: 100000 rows
  Processed chunk 173: 100000 rows
  Processed chunk 174: 100000 rows
  Processed chunk 175: 100000 rows
  Processed chunk 176: 100000 rows
  Processed chunk 177: 100000 rows
  Processed chunk 178: 100000 rows
  Processed chunk 179: 100000 rows
  Processed chunk 180: 100000 rows
  Processed chunk 181: 100000 rows
  Processed chunk 182: 100000 rows
  Processed chunk 183: 100000 rows
  Processed chunk 184: 100000 rows
  Processed chunk 185: 100000 rows
  Processed chunk 186: 100000 rows
  Processed chunk 187: 100000 rows
  Processed chunk 188: 100000 rows
  Processed chunk 189: 100000 rows
  Processed chunk 190: 100000 rows
  Processed chunk 191: 100000 rows
  Processed chunk 192: 100000 rows
  Processed chunk 193: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 194: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 195: 100000 rows
  Processed chunk 196: 100000 rows
  Processed chunk 197: 100000 rows
  Processed chunk 198: 100000 rows
  Processed chunk 199: 100000 rows
  Processed chunk 200: 100000 rows
  Processed chunk 201: 100000 rows
  Processed chunk 202: 100000 rows
  Processed chunk 203: 100000 rows
  Processed chunk 204: 100000 rows
  Processed chunk 205: 100000 rows
  Processed chunk 206: 100000 rows
  Processed chunk 207: 100000 rows
  Processed chunk 208: 100000 rows
  Processed chunk 209: 100000 rows
  Processed chunk 210: 100000 rows
  Processed chunk 211: 100000 rows
  Processed chunk 212: 100000 rows
  Processed chunk 213: 100000 rows
  Processed chunk 214: 100000 rows
  Processed chunk 215: 100000 rows
  Processed chunk 216: 100000 rows
  Processed chunk 217: 100000 rows
  Processed chunk 218: 100000 rows
  Processed chunk 219: 100000 rows
  Processed chunk 220: 100000 rows
  Processed chunk 221: 100000 rows
  Processed chunk 222: 100000 rows
  Processed chunk 223: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 224: 100000 rows
  Processed chunk 225: 100000 rows
  Processed chunk 226: 100000 rows
  Processed chunk 227: 100000 rows
  Processed chunk 228: 100000 rows
  Processed chunk 229: 100000 rows
  Processed chunk 230: 100000 rows
  Processed chunk 231: 100000 rows
  Processed chunk 232: 100000 rows
  Processed chunk 233: 100000 rows
  Processed chunk 234: 100000 rows
  Processed chunk 235: 100000 rows
  Processed chunk 236: 100000 rows
  Processed chunk 237: 100000 rows
  Processed chunk 238: 100000 rows
  Processed chunk 239: 100000 rows
  Processed chunk 240: 100000 rows
  Processed chunk 241: 100000 rows
  Processed chunk 242: 100000 rows
  Processed chunk 243: 100000 rows
  Processed chunk 244: 100000 rows
  Processed chunk 245: 100000 rows
  Processed chunk 246: 100000 rows
  Processed chunk 247: 100000 rows
  Processed chunk 248: 100000 rows
  Processed chunk 249: 100000 rows
  Processed chunk 250: 100000 rows
  Processed chunk 251: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 252: 100000 rows
  Processed chunk 253: 100000 rows
  Processed chunk 254: 100000 rows
  Processed chunk 255: 100000 rows
  Processed chunk 256: 100000 rows
  Processed chunk 257: 100000 rows
  Processed chunk 258: 100000 rows
  Processed chunk 259: 100000 rows
  Processed chunk 260: 100000 rows
  Processed chunk 261: 100000 rows
  Processed chunk 262: 100000 rows
  Processed chunk 263: 100000 rows
  Processed chunk 264: 100000 rows
  Processed chunk 265: 100000 rows
  Processed chunk 266: 100000 rows
  Processed chunk 267: 100000 rows
  Processed chunk 268: 100000 rows
  Processed chunk 269: 100000 rows
  Processed chunk 270: 100000 rows
  Processed chunk 271: 100000 rows
  Processed chunk 272: 100000 rows
  Processed chunk 273: 100000 rows
  Processed chunk 274: 100000 rows
  Processed chunk 275: 100000 rows
  Processed chunk 276: 100000 rows
  Processed chunk 277: 100000 rows
  Processed chunk 278: 100000 rows
  Processed chunk 279: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 280: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 281: 100000 rows
  Processed chunk 282: 100000 rows
  Processed chunk 283: 100000 rows
  Processed chunk 284: 100000 rows
  Processed chunk 285: 100000 rows
  Processed chunk 286: 100000 rows
  Processed chunk 287: 100000 rows
  Processed chunk 288: 100000 rows
  Processed chunk 289: 100000 rows
  Processed chunk 290: 100000 rows
  Processed chunk 291: 100000 rows
  Processed chunk 292: 100000 rows
  Processed chunk 293: 100000 rows
  Processed chunk 294: 100000 rows
  Processed chunk 295: 100000 rows
  Processed chunk 296: 100000 rows
  Processed chunk 297: 100000 rows
  Processed chunk 298: 100000 rows
  Processed chunk 299: 100000 rows
  Processed chunk 300: 100000 rows
  Processed chunk 301: 100000 rows
  Processed chunk 302: 100000 rows
  Processed chunk 303: 100000 rows
  Processed chunk 304: 100000 rows
  Processed chunk 305: 100000 rows
  Processed chunk 306: 100000 rows
  Processed chunk 307: 100000 rows
  Processed chunk 308: 100000 rows
  Processed chunk 309: 100000 rows
  Processed chunk 310: 100000 rows
  Processed chunk 311: 100000 rows
  Processed chunk 312: 100000 rows
  Processed chunk 313: 100000 rows
  Processed chunk 314: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 315: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 316: 100000 rows
  Processed chunk 317: 100000 rows
  Processed chunk 318: 100000 rows
  Processed chunk 319: 100000 rows
  Processed chunk 320: 100000 rows
  Processed chunk 321: 100000 rows
  Processed chunk 322: 100000 rows
  Processed chunk 323: 100000 rows
  Processed chunk 324: 100000 rows
  Processed chunk 325: 100000 rows
  Processed chunk 326: 100000 rows
  Processed chunk 327: 100000 rows
  Processed chunk 328: 100000 rows
  Processed chunk 329: 100000 rows
  Processed chunk 330: 100000 rows
  Processed chunk 331: 100000 rows
  Processed chunk 332: 100000 rows
  Processed chunk 333: 100000 rows
  Processed chunk 334: 100000 rows
  Processed chunk 335: 100000 rows
  Processed chunk 336: 100000 rows
  Processed chunk 337: 100000 rows
  Processed chunk 338: 100000 rows
  Processed chunk 339: 100000 rows
  Processed chunk 340: 100000 rows
  Processed chunk 341: 100000 rows
  Processed chunk 342: 100000 rows
  Processed chunk 343: 100000 rows
  Processed chunk 344: 100000 rows
  Processed chunk 345: 100000 rows
  Processed chunk 346: 100000 rows
  Processed chunk 347: 100000 rows
  Processed chunk 348: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 349: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 350: 100000 rows
  Processed chunk 351: 100000 rows
  Processed chunk 352: 100000 rows
  Processed chunk 353: 100000 rows
  Processed chunk 354: 100000 rows
  Processed chunk 355: 100000 rows
  Processed chunk 356: 100000 rows
  Processed chunk 357: 100000 rows
  Processed chunk 358: 100000 rows
  Processed chunk 359: 100000 rows
  Processed chunk 360: 100000 rows
  Processed chunk 361: 100000 rows
  Processed chunk 362: 100000 rows
  Processed chunk 363: 100000 rows
  Processed chunk 364: 100000 rows
  Processed chunk 365: 100000 rows
  Processed chunk 366: 100000 rows
  Processed chunk 367: 100000 rows
  Processed chunk 368: 100000 rows
  Processed chunk 369: 100000 rows
  Processed chunk 370: 100000 rows
  Processed chunk 371: 100000 rows
  Processed chunk 372: 100000 rows
  Processed chunk 373: 100000 rows
  Processed chunk 374: 100000 rows
  Processed chunk 375: 100000 rows
  Processed chunk 376: 100000 rows
  Processed chunk 377: 100000 rows
  Processed chunk 378: 100000 rows
  Processed chunk 379: 100000 rows
  Processed chunk 380: 100000 rows
  Processed chunk 381: 100000 rows
C:\MIT805_A1_Data\scripts\combine_all_csvs.py:34: DtypeWarning: Columns (6) have mixed types. Specify dtype option on import or set low_memory=False.
  for i, chunk in enumerate(pd.read_csv(local_path, chunksize=chunk_size)):
  Processed chunk 382: 100000 rows
  Processed chunk 383: 100000 rows
  Processed chunk 384: 10226 rows
âœ… Processed 38,310,226 rows from yellow data

Combining all data... (Total: 114,930,678 rows)
Saving combined file with 114,930,678 rows...
Uploading to HDFS: /MIT805A1/combined_all_yellow_taxi_data/nyc_all_yellow_taxi_data_2023_2025_combined.csv
âœ… Successfully created combined file: /MIT805A1/combined_all_yellow_taxi_data/nyc_all_yellow_taxi_data_2023_2025_combined.csv
ðŸ“Š File size: 13.37 GB
ðŸ“Š Total rows: 114,930,678
ðŸ“Š Columns: 22
ðŸ“Š Source distribution:
   yellow: 114,930,678 rows (100.0%)

C:\MIT805_A1_Data\scripts>